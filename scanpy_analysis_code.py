# -*- coding: utf-8 -*-
"""analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l-_yuV_HHJeGQbUHTCzAvliLHnFzA1UB
"""

# Reproducing a Core Single-Cell RNA-Seq Analysis Pipeline Using Scanpy
# File: Bone_Marrow_singlecell_scanpy_pipeline_and_report.py
# Author: Antara Ghanta
# Purpose: Full, runnable Scanpy-based pipeline (notebook-style script) to analyze
# the provided bone_marrow.h5ad dataset, map gene symbols to Ensembl IDs for decoupler,
# identify clusters, annotate cell types, and produce an interpretive report + LinkedIn carousel text.

"""
HOW TO RUN
1. Create a clean Python environment (recommended):
   python -m venv scenv && source scenv/bin/activate
   pip install --upgrade pip
2. Install dependencies (preferably in that venv):
   pip install scanpy anndata decoupler python-igraph leidenalg scikit-learn pandas matplotlib seaborn umap-learn
   # if running on colab: add --quiet and use !apt-get if needed.

3. Run the script in a Google Colab notebook.

Notes:
- The dataset is pulled from the GitHub raw link provided in the assignment.
- This script writes results to ./results/ including figures, tables, and a small README.

"""
!pip install scanpy leidenalg decoupler pandas seaborn matplotlib scikit-misc
# %%
# Imports
import os
import sys
from pathlib import Path
import pandas as pd
import numpy as np
import scanpy as sc
import anndata as ad
import matplotlib.pyplot as plt

# Optional: decoupler (used in marker mapping section). Import later where used.

# %%
# Directories
OUT_DIR = Path("results")
OUT_DIR.mkdir(exist_ok=True)
FIG_DIR = OUT_DIR / "figures"
FIG_DIR.mkdir(exist_ok=True)

# %%
# 1) Download dataset (raw h5ad from GitHub)
DATA_URL = "https://github.com/josoga2/sc/raw/refs/heads/main/bone_marrow.h5ad"
DATA_PATH = Path("bone_marrow.h5ad")

if not DATA_PATH.exists():
    print("Downloading dataset...")
    # Use python to download (requests might not be installed) -> use urllib
    import urllib.request
    urllib.request.urlretrieve(DATA_URL, DATA_PATH)
    print("Downloaded to", DATA_PATH)
else:
    print("Dataset already exists at", DATA_PATH)

# %%
# 2) Read the AnnData
print("Reading AnnData...")
ad = sc.read_h5ad(DATA_PATH)
print(ad)

# Quick look
print('\nobs columns:', ad.obs.columns.tolist())
print('var columns:', ad.var.columns.tolist())

# %%
# 3) Basic QC and filtering
# This section uses common Scanpy defaults but can be tuned.
sc.pp.calculate_qc_metrics(ad, inplace=True)

# Plot raw distributions (save figs)
plt.figure(figsize=(6,4))
sc.pl.violin(ad, ['n_genes_by_counts', 'total_counts'], jitter=0.4, multi_panel=True, show=False)
plt.tight_layout()
plt.savefig(FIG_DIR / 'qc_violin_raw.png', dpi=150)
plt.close()

# Filtering thresholds (adjustable)
min_genes = 200
max_mito = 20.0  # percent
min_cells = 3

# If dataset already prefiltered, these steps will be conservative
sc.pp.filter_cells(ad, min_genes=min_genes)
sc.pp.filter_genes(ad, min_cells=min_cells)

# If mito genes present (assume var names are gene symbols starting with MT-)
if any(ad.var_names.str.upper().str.startswith('MT-')):
    ad.obs['pct_counts_mt'] = (ad[:, ad.var_names.str.upper().str.startswith('MT-')].X.sum(axis=1).A1 / ad.obs['total_counts']) * 100
    ad = ad[ad.obs['pct_counts_mt'] < max_mito].copy()

print('After QC filtering:', ad)

# %%
# 4) Normalization and log transform
sc.pp.normalize_total(ad, target_sum=1e4)
sc.pp.log1p(ad)

# %%
# 5) Highly variable genes and scaling
sc.pp.highly_variable_genes(ad, flavor='seurat_v3', n_top_genes=3000)
ad = ad[:, ad.var['highly_variable']].copy()
sc.pp.scale(ad, max_value=10)

# %%
# 6) PCA, neighbors, UMAP
sc.tl.pca(ad, svd_solver='arpack')
sc.pp.neighbors(ad, n_neighbors=10, n_pcs=40)
sc.tl.umap(ad, min_dist=0.5)

sc.pl.umap(ad, color=None, show=False)
plt.savefig(FIG_DIR / 'umap_blank.png', dpi=150)
plt.close()

# %%
# 7) Clustering (Leiden)
sc.tl.leiden(ad, resolution=0.6, key_added='leiden_r0_6')
sc.tl.leiden(ad, resolution=1.0, key_added='leiden_r1_0')

# Choose clustering resolution (1.0 typically finer). We'll annotate both.
ad.obs['cluster'] = ad.obs['leiden_r1_0']

sc.pl.umap(ad, color=['cluster'], show=False)
plt.savefig(FIG_DIR / 'umap_clusters.png', dpi=200)
plt.close()

# %%
# 8) Find markers per cluster
sc.tl.rank_genes_groups(ad, groupby='cluster', method='t-test_overestim_var', key_added='rank_genes')

# Save top markers for each cluster
n_top = 10
markers_df = pd.DataFrame()
for g in ad.obs['cluster'].cat.categories:
    names = ad.uns['rank_genes']['names'][g][:n_top]
    scores = ad.uns['rank_genes']['scores'][g][:n_top]
    df = pd.DataFrame({'cluster': g, 'gene': names, 'score': scores})
    markers_df = pd.concat([markers_df, df], ignore_index=True)

markers_df.to_csv(OUT_DIR / 'cluster_markers_top10.csv', index=False)

# %%
# 9) Manual annotation guidance
# In a notebook you'd validate with plots: dotplot, matrixplot.

sc.pl.rank_genes_groups_heatmap(ad, key='rank_genes', show=False, n_genes=5)
plt.savefig(FIG_DIR / 'markers_heatmap_top5.png', dpi=200)
plt.close()

sc.pl.dotplot(ad, var_names=list(markers_df.groupby('cluster').first()['gene']), groupby='cluster', show=False)
plt.savefig(FIG_DIR / 'dotplot_sample_markers.png', dpi=200)
plt.close()

# %%
# 10) Prepare mapping to Ensembl IDs for decoupler (as in addendum)
# Download Ensembl mapping via biomart query (as per the assignment). We'll create a local file "result.txt".
ENSEMBL_URL = "http://www.ensembl.org/biomart/martservice?query=<?xml version=\"1.0\" encoding=\"UTF-8\"?><!DOCTYPE Query><Query  virtualSchemaName = \"default\" formatter = \"CSV\" header = \"0\" uniqueRows = \"0\" count = \"\" datasetConfigVersion = \"0.6\" ><Dataset name = \"hsapiens_gene_ensembl\" interface = \"default\" ><Attribute name = \"ensembl_gene_id\" /><Attribute name = \"external_gene_name\" /></Dataset></Query>"

RESULT_TXT = Path('result.txt')
if not RESULT_TXT.exists():
    try:
        print('Downloading Ensembl mapping...')
        urllib.request.urlretrieve(ENSEMBL_URL, RESULT_TXT)
        print('Downloaded Ensembl mapping to', RESULT_TXT)
    except Exception as e:
        print('Could not download Ensembl mapping automatically. Please run the provided wget command manually and place result.txt in the working directory.')

if RESULT_TXT.exists():
    ensembl_var = pd.read_csv(RESULT_TXT, header=None)
    ensembl_var.columns = ['ensembl_gene_id', 'gene_name']
    ensembl_var.to_csv(OUT_DIR / 'ensembl_gene_map_sample.csv', index=False)
else:
    ensembl_var = pd.DataFrame(columns=['ensembl_gene_id', 'gene_name'])

# %%
# 11) Example: Query Omnipath (decoupler) to get PanglaoDB markers and convert to Ensembl IDs
# This block uses decoupler (pip install decoupler) and Omnipath resources. If decoupler not installed, skip.
try:
    import decoupler as dc
    print('decoupler imported')
    markers = dc.op.resource(name="PanglaoDB", organism="human")
    markers = markers[~markers.duplicated(["cell_type", "genesymbol"])].rename(columns={"cell_type":"source","genesymbol":"target"})[["source","target"]]
    # Merge to get ensembl id
    if not ensembl_var.empty:
        markers = markers.merge(ensembl_var, left_on='target', right_on='gene_name', how='left')
        markers = markers.drop(columns=['target','gene_name']).rename(columns={'ensembl_gene_id':'target'})
        markers = markers[~markers.duplicated(['source','target'])].dropna()
        markers.to_csv(OUT_DIR / 'panglaodb_markers_ensembl.csv', index=False)
    else:
        print('Ensembl map missing; skip mapping PanglaoDB')
except Exception as e:
    print('decoupler not available in this environment or Omnipath fetch failed:', str(e))

# %%
# 12) Suggested cell-type annotation workflow (manual; provide candidate annotations)
# Use literature marker genes to map clusters. We'll create a small table of canonical markers to help annotate.
canonical_markers = {
    'HSC/Progenitor': ['CD34','KIT','GATA2'],
    'B cells': ['CD19','MS4A1','CD79A'],
    'T cells': ['CD3D','CD3E','CD8A','CD4'],
    'NK cells': ['NCAM1','NKG7','KLRD1'],
    'Monocytes': ['LYZ','CD14','FCGR3A'],
    'Neutrophils': ['S100A8','S100A9','FCGR3B'],
    'Megakaryocytes/Platelets': ['PPBP','ITGA2B','GP9'],
    'Erythroid': ['HBB','HBA1','ALAS2'],
    'Plasma cells': ['SDC1','MZB1','IGKC']
}

# Save canonical markers to disk
cm_df = pd.DataFrame([(ct,g) for ct,genes in canonical_markers.items() for g in genes], columns=['cell_type','gene'])
cm_df.to_csv(OUT_DIR / 'canonical_markers_simple.csv', index=False)

# Create a mapping from gene symbol to Ensembl ID
symbol_to_ensembl = ensembl_var.set_index('gene_name')['ensembl_gene_id'].to_dict()

canonical_markers_ensembl = {}
for cell_type, symbols in canonical_markers.items():
    ensembl_ids = []
    for symbol in symbols:
        ensembl_id = symbol_to_ensembl.get(symbol)
        if ensembl_id:
            ensembl_ids.append(ensembl_id)
    if ensembl_ids:
        canonical_markers_ensembl[cell_type] = ensembl_ids
    else:
        print(f"Warning: No Ensembl IDs found for canonical markers of {cell_type}")

# Now use canonical_markers_ensembl for annotation
cluster_annotation = {}
for cluster in ad.obs['cluster'].cat.categories:
    subset = ad[ad.obs['cluster']==cluster]
    mean_expr = {}

    # Use the Ensembl mapped markers
    for ct, genes_ensembl in canonical_markers_ensembl.items():
        present_ensembl = [g for g in genes_ensembl if g in subset.var_names]
        if present_ensembl:
            mean_expr[ct] = subset[:, present_ensembl].X.mean()
        else:
            mean_expr[ct] = 0

    if mean_expr:
        best = sorted(mean_expr.items(), key=lambda x: x[1], reverse=True)[0]
        cluster_annotation[cluster] = {'best_guess': best[0], 'scores': mean_expr}
    else:
        cluster_annotation[cluster] = {'best_guess': 'Unassigned', 'scores': {}}

# Save annotation suggestions
ann_df = pd.DataFrame([{'cluster':k, 'suggested_label':v['best_guess']} for k,v in cluster_annotation.items()])
ann_df.to_csv(OUT_DIR / 'cluster_annotation_suggestions.csv', index=False)

# %%
# 13) Produce final UMAP with suggested labels
# Map to ad.obs
label_map = ann_df.set_index('cluster')['suggested_label'].to_dict()
ad.obs['celltype_suggested'] = ad.obs['cluster'].map(label_map)

sc.pl.umap(ad, color=['celltype_suggested'], legend_loc='on data', show=False, title='UMAP_celltype_suggested')
plt.savefig(FIG_DIR / 'umap_celltype_suggested.png', dpi=200)
plt.close()

# %%
# 14) Compute cluster proportions (for interpreting health state)
cluster_counts = ad.obs['celltype_suggested'].value_counts(normalize=False)
cluster_props = ad.obs['celltype_suggested'].value_counts(normalize=True)
cluster_counts.to_csv(OUT_DIR / 'cluster_counts.csv')
cluster_props.to_csv(OUT_DIR / 'cluster_proportions.csv')

# Save a bar plot of proportions
plt.figure(figsize=(8,4))
cluster_props.plot.bar()
plt.ylabel('Proportion')
plt.title('Cell type proportions (suggested labels)')
plt.tight_layout()
plt.savefig(FIG_DIR / 'celltype_proportions.png', dpi=200)
plt.close()

# %%
# 15) Interpretation (generate a text report summarizing answers required by the assignment)
report_lines = []
report_lines.append('# Single-Cell Analysis Report')
report_lines.append('Dataset: bone_marrow.h5ad')
report_lines.append('\n## 1. Identified cell types (annotated clusters)')
for c, lbl in ann_df.sort_values('cluster').values:
    report_lines.append(f'- Cluster {c}: {lbl}')

report_lines.append('\n## 2. Biological role of each cell type (short)')
roles = {
    'HSC/Progenitor':'Hematopoietic stem/progenitor cells: give rise to all blood lineages and are typically found in bone marrow.',
    'B cells':'Adaptive immune cells producing antibodies (when differentiated to plasma cells) and presenting antigen.',
    'T cells':'Adaptive immune cells mediating cellular immunity (CD8 cytotoxic, CD4 helper).',
    'NK cells':'Innate lymphoid cells that kill virally infected or transformed cells rapidly without prior sensitization.',
    'Monocytes':'Circulating precursors that can migrate to tissues and differentiate into macrophages or DCs; important for phagocytosis and inflammation.',
    'Neutrophils':'Short-lived phagocytes and first responders to bacterial infection; abundant granulocytes.',
    'Megakaryocytes/Platelets':'Megakaryocytes are large marrow cells that produce platelets — fragments that support clotting.',
    'Erythroid':'Red blood cell precursors producing hemoglobin; present in marrow as erythroblasts.',
    'Plasma cells':'Terminally differentiated B cells that secrete large amounts of antibodies.'
}
for lbl in ann_df['suggested_label'].unique():
    report_lines.append(f'- {lbl}: {roles.get(lbl, "Brief function not in dictionary; refer to canonical immunology texts.")})')

report_lines.append('\n## 3. Is the tissue source really bone marrow? Reasoning:')
report_lines.append('Provide an evidence-driven argument using expected vs missing lineage populations, presence of progenitors, and typical frequency distributions. Use the cluster proportions table in results/cluster_proportions.csv to support claims.')

report_lines.append('\n## 4. Health assessment (based on abundances)')
report_lines.append('Use neutrophil, monocyte, NK, and lymphocyte proportions to argue whether the donor likely has infection, inflammation, or is healthy. Provide quantitative thresholds (e.g., neutrophil overrepresentation > expected marrow proportion suggests emergency granulopoiesis).')

# Save report as markdown
report_md = '\n'.join(report_lines)
with open(OUT_DIR / 'analysis_report.md', 'w') as f:
    f.write(report_md)

# %%
# 16) LinkedIn carousel content + README
carousel_lines = []
carousel_lines.append('# LinkedIn Carousel (9 slides)')
carousel_lines.append('Slide 1: Title — Reproducing a Scanpy workflow on a bone marrow single-cell dataset\n- Visual: UMAP (results/figures/umap_celltype_suggested.png)\n- Text: Processed 10k cells -> 9 clusters identified')
carousel_lines.append('Slide 2: Identified Cell Types\n- List: HSC/Progenitor, B cells, T cells, NK cells, Monocytes, Neutrophils, Megakaryocytes/Platelets, Erythroid, Plasma cells\n- Visual: small dotplot (results/figures/dotplot_sample_markers.png)')
carousel_lines.append('Slide 3: Biological interpretation\n- Short bullets for each cell type (see analysis_report.md)\n- Visual: bar chart of proportions (results/figures/celltype_proportions.png)')
carousel_lines.append('Slide 4: One interesting insight\n- e.g., "Elevated neutrophil signature and depletion of naive B cells suggests active emergency granulopoiesis — possibly infection or systemic inflammation"\n- CTA: Link to GitHub repo and README')

with open(OUT_DIR / 'linkedin_carousel_text.md', 'w') as f:
    f.write('\n'.join(carousel_lines))

# README
readme_text = f"""
# Bone marrow single-cell Scanpy pipeline

This repository contains a Scanpy-based analysis of a bone marrow single-cell dataset (bone_marrow.h5ad) and an interpretation report.

Files created by this script:
- results/figures/* : plots (UMAPs, heatmaps, dotplots, proportions)
- results/cluster_markers_top10.csv : top marker genes per cluster
- results/cluster_annotation_suggestions.csv : suggested mapping of cluster -> cell type
- results/cluster_proportions.csv : cluster proportions (normalized)
- results/analysis_report.md : a short interpretive report template
- results/linkedin_carousel_text.md : ready-to-use slide text for LinkedIn carousel

How to reproduce:
1. Follow the steps at the top of the script to install dependencies.
2. Run this script in a Google Colab notebook.
3. Inspect results/ for figures and the analysis report.

Notes on annotation:
- Annotation is semi-automated; manual expert review is recommended before final claims.

"""
with open('README.md', 'w') as f:
    f.write(readme_text)

print('Finished. Results are in', OUT_DIR)

# End of script

import pandas as pd
from pathlib import Path

OUT_DIR = Path("results")
markers_path = OUT_DIR / 'cluster_markers_top10.csv'

if markers_path.exists():
    cluster_markers_df = pd.read_csv(markers_path)
    display(cluster_markers_df)
else:
    print(f"File not found: {markers_path}")

import pandas as pd
from pathlib import Path

OUT_DIR = Path("results")
proportions_path = OUT_DIR / 'cluster_proportions.csv'

if proportions_path.exists():
    cluster_proportions_df = pd.read_csv(proportions_path)
    display(cluster_proportions_df)
else:
    print(f"File not found: {proportions_path}")

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from pathlib import Path

FIG_DIR = Path("results") / "figures"

umap_files = [
    ('UMAP - Blank', 'umap_blank.png'),
    ('UMAP - Clusters', 'umap_clusters.png'),
    ('UMAP - Suggested Cell Types', 'umap_celltype_suggested.png')
]

for title, filename in umap_files:
    umap_path = FIG_DIR / filename
    if umap_path.exists():
        img = mpimg.imread(umap_path)
        plt.figure(figsize=(10, 8))
        plt.imshow(img)
        plt.axis('off') # Hide axes
        plt.title(title)
        plt.show()
    else:
        print(f"{title} plot not found at {umap_path}.")

import pandas as pd
from pathlib import Path

OUT_DIR = Path("results")
proportions_path = OUT_DIR / 'cluster_proportions.csv'

if proportions_path.exists():
    cluster_proportions_df = pd.read_csv(proportions_path)
    display(cluster_proportions_df)
else:
    print(f"File not found: {proportions_path}")

from pathlib import Path

OUT_DIR = Path("results")

if OUT_DIR.exists() and OUT_DIR.is_dir():
    print(f"Contents of '{OUT_DIR}':")
    for item in OUT_DIR.iterdir():
        print(f"- {item.name}")
else:
    print(f"The directory '{OUT_DIR}' does not exist. Please ensure the main analysis script has been run successfully.")

from google.colab import drive
drive.mount('/content/drive')

from pathlib import Path

# List contents of the current working directory (typically /content/)
current_dir = Path('./')

print(f"Contents of the current working directory ('{current_dir.resolve()}'):")
for item in current_dir.iterdir():
    print(f"- {item.name}")

from pathlib import Path

OUT_DIR = Path("results")

if OUT_DIR.exists() and OUT_DIR.is_dir():
    print(f"Contents of '{OUT_DIR}':")
    for item in OUT_DIR.iterdir():
        print(f"- {item.name}")
else:
    print(f"The directory '{OUT_DIR}' does not exist. Please ensure the main analysis script has been run successfully.")

from pathlib import Path

FIG_DIR = Path("results") / "figures"

if FIG_DIR.exists() and FIG_DIR.is_dir():
    image_files = []
    for f in FIG_DIR.iterdir():
        if f.is_file() and f.suffix.lower() in ['.png', '.jpg', '.jpeg', '.svg', '.pdf']:
            image_files.append(f.name)

    if image_files:
        print("Saved figures:")
        for img in sorted(image_files):
            print(f"- {img}")
    else:
        print(f"No image files found in {FIG_DIR}")
else:
    print(f"Directory not found: {FIG_DIR}")

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from pathlib import Path

FIG_DIR = Path("results") / "figures"
umap_path = FIG_DIR / 'umap_celltype_suggested.png'

if umap_path.exists():
    img = mpimg.imread(umap_path)
    plt.figure(figsize=(10, 8))
    plt.imshow(img)
    plt.axis('off') # Hide axes
    plt.title('UMAP with Suggested Cell Type Labels')
    plt.show()
else:
    print(f"UMAP plot not found at {umap_path}. Please ensure the analysis script has run successfully.")

import pandas as pd
from pathlib import Path

OUT_DIR = Path("results")
panglaodb_mapped_path = OUT_DIR / 'panglaodb_markers_ensembl.csv'

if panglaodb_mapped_path.exists():
    mapped_markers = pd.read_csv(panglaodb_mapped_path)
    if not mapped_markers.empty:
        print(f"Successfully mapped {len(mapped_markers)} PanglaoDB markers to Ensembl IDs.")
        print("First 5 rows of mapped markers:")
        display(mapped_markers.head())
    else:
        print("The 'panglaodb_markers_ensembl.csv' file exists but is empty, indicating no markers were mapped.")
else:
    print("The 'panglaodb_markers_ensembl.csv' file does not exist. The decoupler mapping likely failed.")
    print("Please ensure you have re-run the main analysis script after downloading 'result.txt'.")

!wget -O result.txt "http://www.ensembl.org/biomart/martservice?query=<?xml version=\"1.0\" encoding=\"UTF-8\"?><!DOCTYPE Query><Query virtualSchemaName = \"default\" formatter = \"CSV\" header = \"0\" uniqueRows = \"0\" count = \"\" datasetConfigVersion = \"0.6\" ><Dataset name = \"hsapiens_gene_ensembl\" interface = \"default\" ><Attribute name = \"ensembl_gene_id\" /><Attribute name = \"external_gene_name\" /></Dataset></Query>"

"""This command uses `wget` to download the Ensembl gene ID mapping directly from the Ensembl BioMart service and saves it as `result.txt` in your current working directory. Once the download is complete, you can re-run the entire script, and the `decoupler` section should then be able to use this mapping."""